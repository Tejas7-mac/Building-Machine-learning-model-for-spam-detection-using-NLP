{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "# 1.Building Machine Learning Classifiers: Building a basic Random Forest model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Random Forest:- Ensemble learning method that constructs a collection of decision tree and then aggregates the prediction of each tree to determine the final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "      <th>7531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.101347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.079857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7534 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body_len  punct%         0    1    2    3    4    5    6    7  ...  7522  \\\n",
       "0        24    25.0  0.101347  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1       128     4.7  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2        39    15.4  0.079857  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3        49     4.1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4       116     6.9  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   7523  7524  7525  7526  7527  7528  7529  7530  7531  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7534 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "ps=nltk.PorterStemmer()\n",
    "data=pd.read_csv('SMSSpamCollection.tsv',sep='\\t')\n",
    "data.columns=['label','Body_text']\n",
    "#function for\n",
    "#1.body length\n",
    "# 2.body punctuation\n",
    "def count_punct(text):\n",
    "    count=sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text)-text.count(\" \")),3)*100\n",
    "data['Body_len']=data['Body_text'].apply(lambda x:len(x)-x.count(\" \"))\n",
    "data[\"punct%\"]=data[\"Body_text\"].apply(lambda x:count_punct(x))\n",
    "#cleaning the text function\n",
    "def clean_text(text):\n",
    "    text==\"\".join([word.lower() for word in text if word  not in string.punctuation])\n",
    "    tokens=re.split('\\W+',text)\n",
    "    text=[ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "#vectorizing\n",
    "tfidf_vect=TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf=tfidf_vect.fit_transform(data['Body_text'])\n",
    "\n",
    "X_feature=pd.concat([data['Body_len'],data[\"punct%\"],pd.DataFrame(X_tfidf.toarray())],axis=1)\n",
    "X_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Random Forest classifier Attributes and  HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_n_features', '_estimator_type', '_get_param_names', '_get_tags', '_make_estimator', '_more_tags', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_set_oob_score', '_validate_X_predict', '_validate_data', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importances_:- this will out puts the value of each feature to the Model\n",
    "#fit:- helps to fit the model and stores the object\n",
    "#predict:- this model is used to prediction by using the objects created by the fit model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring random forest classifier through Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "#kfold helps in splliting the datasets\n",
    "#cross_val_score will help us to get the actuall scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9793722 , 0.98384201, 0.98114901, 0.97396768, 0.98204668])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_jobs=-1)\n",
    "#n_jobs to -1 will help us to run faster by bulding the decision tree in parallel \n",
    "k_fold=KFold(n_splits=5)\n",
    "#n_splits will help in splitting the dataset into the number we assign to it.\n",
    "cross_val_score(rf,X_feature,data['label'],cv=k_fold,scoring='accuracy',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Building Machine Learning Classifier:- Random Forest on a hold out test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring RandomForestClassifier through  HoldOut set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 4 datasets\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_feature,data['label'],test_size=0.2)\n",
    "#0.2=20% is the test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1=RandomForestClassifier(n_estimators=50,max_depth=20,n_jobs=-1)\n",
    "#max_depth will give the depth of the decision tree to 20 default value is None if u use default value it will build the decision tree as deep it can build.\n",
    "rf_model=rf1.fit(x_train,y_train)\n",
    "#i have explained the fit function above in cell number 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.058253796146168796, 1898),\n",
       " (0.04948181796118803, 6906),\n",
       " (0.04380202267316266, 'Body_len'),\n",
       " (0.023914451157795155, 4574),\n",
       " (0.01971188002947149, 7414),\n",
       " (0.017719719415993592, 3130),\n",
       " (0.017579632489775118, 1039),\n",
       " (0.015885625174227522, 0),\n",
       " (0.015825236745703086, 5412),\n",
       " (0.015498195226661484, 6623)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_,x_train.columns),reverse=True)[0:10]\n",
    "#sort is used to sort them in order and reverse will make the default ascending order to descending order"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#its showing that the body_len is the most important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf_model.predict(x_test)\n",
    "precision,recall,fscore,support=score(y_test,y_pred,pos_label='spam',average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 1.0 / Recall:0.667 / Acuracy:0.956\n"
     ]
    }
   ],
   "source": [
    "print('precision: {} / Recall:{} / Acuracy:{}'.format(round(precision,3),\n",
    "                                                     round(recall,3),\n",
    "                                                     round((y_pred==y_test).sum()/len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The meaning of the above out put is shown below Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Building the Machine learning cassifiers: explore random Forest model with Grid-search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Grid Search:- Exhaustively search all parameter combinations in a given grid to determine the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our own grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_feature,data['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Rf(n_est,depth):\n",
    "    rf1=RandomForestClassifier(n_estimators=n_est,max_depth=depth,n_jobs=-1)\n",
    "    rf_model=rf1.fit(x_train,y_train)\n",
    "    y_pred=rf_model.predict(x_test)\n",
    "    precision,recall,fscore,support=score(y_test,y_pred,pos_label='spam',average='binary')\n",
    "    print('EST:{}/ Depth:{} /precision: {} / Recall:{} / Acuracy:{}'.format(n_est,depth,round(precision,3),\n",
    "                                                     round(recall,3),\n",
    "                                                     round((y_pred==y_test).sum()/len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EST:10/ Depth:10 /precision: 1.0 / Recall:0.307 / Acuracy:0.899\n",
      "EST:10/ Depth:20 /precision: 1.0 / Recall:0.644 / Acuracy:0.948\n",
      "EST:10/ Depth:30 /precision: 1.0 / Recall:0.706 / Acuracy:0.957\n",
      "EST:10/ Depth:None /precision: 1.0 / Recall:0.761 / Acuracy:0.965\n",
      "EST:50/ Depth:10 /precision: 1.0 / Recall:0.331 / Acuracy:0.902\n",
      "EST:50/ Depth:20 /precision: 1.0 / Recall:0.626 / Acuracy:0.945\n",
      "EST:50/ Depth:30 /precision: 1.0 / Recall:0.748 / Acuracy:0.963\n",
      "EST:50/ Depth:None /precision: 1.0 / Recall:0.828 / Acuracy:0.975\n",
      "EST:100/ Depth:10 /precision: 1.0 / Recall:0.294 / Acuracy:0.897\n",
      "EST:100/ Depth:20 /precision: 1.0 / Recall:0.632 / Acuracy:0.946\n",
      "EST:100/ Depth:30 /precision: 1.0 / Recall:0.761 / Acuracy:0.965\n",
      "EST:100/ Depth:None /precision: 1.0 / Recall:0.81 / Acuracy:0.972\n"
     ]
    }
   ],
   "source": [
    "for n_est in[10,50,100]:\n",
    "    for depth in [10,20,30,None]:\n",
    "        train_Rf(n_est,depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating  Random Forest With Grid SearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CROSS VALIDATION:- Divide a dataset into k subsets and repeat the hould out method K times with a different subset is used as the hould out set in each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "      <th>7531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.101347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.079857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7534 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body_len  punct%         0    1    2    3    4    5    6    7  ...  7522  \\\n",
       "0        24    25.0  0.101347  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1       128     4.7  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2        39    15.4  0.079857  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3        49     4.1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4       116     6.9  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   7523  7524  7525  7526  7527  7528  7529  7530  7531  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7534 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import string\n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "ps=nltk.PorterStemmer()\n",
    "data=pd.read_csv('SMSSpamCollection.tsv',sep='\\t')\n",
    "data.columns=['label','Body_text']\n",
    "#function for\n",
    "#1.body length\n",
    "# 2.body punctuation\n",
    "def count_punct(text):\n",
    "    count=sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text)-text.count(\" \")),3)*100\n",
    "data['Body_len']=data['Body_text'].apply(lambda x:len(x)-x.count(\" \"))\n",
    "data[\"punct%\"]=data[\"Body_text\"].apply(lambda x:count_punct(x))\n",
    "#cleaning the text function\n",
    "def clean_text(text):\n",
    "    text==\"\".join([word.lower() for word in text if word  not in string.punctuation])\n",
    "    tokens=re.split('\\W+',text)\n",
    "    text=[ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "#vectorizing\n",
    "tfidf_vect=TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf=tfidf_vect.fit_transform(data['Body_text'])\n",
    "X_tfidf_feat=pd.concat([data['Body_len'],data[\"punct%\"],pd.DataFrame(X_tfidf.toarray())],axis=1)\n",
    "#count_vectorizer\n",
    "count_vect=CountVectorizer(analyzer=clean_text)\n",
    "x_count=count_vect.fit_transform(data['Body_text'])\n",
    "x_count_feat=pd.concat([data['Body_len'],data[\"punct%\"],pd.DataFrame(X_tfidf.toarray())],axis=1)\n",
    "                                 \n",
    "x_count_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the parameter setting using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48.655709</td>\n",
       "      <td>7.855495</td>\n",
       "      <td>0.597819</td>\n",
       "      <td>0.197063</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978819</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30.721205</td>\n",
       "      <td>1.732543</td>\n",
       "      <td>0.560376</td>\n",
       "      <td>0.092377</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.978639</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55.037477</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>0.179367</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978460</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.834200</td>\n",
       "      <td>15.848334</td>\n",
       "      <td>1.129819</td>\n",
       "      <td>0.748795</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978460</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.799014</td>\n",
       "      <td>0.701959</td>\n",
       "      <td>0.724876</td>\n",
       "      <td>0.155050</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978281</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11      48.655709      7.855495         0.597819        0.197063   \n",
       "10      30.721205      1.732543         0.560376        0.092377   \n",
       "8       55.037477      1.018602         0.954751        0.179367   \n",
       "5       49.834200     15.848334         1.129819        0.748795   \n",
       "7       29.799014      0.701959         0.724876        0.155050   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "11            None                300   \n",
       "10            None                150   \n",
       "8               90                300   \n",
       "5               60                300   \n",
       "7               90                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.979372   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.978475   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.978475   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.979372   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.977578   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "11           0.979354           0.978456           0.977558   \n",
       "10           0.980251           0.979354           0.976661   \n",
       "8            0.980251           0.978456           0.975763   \n",
       "5            0.978456           0.979354           0.975763   \n",
       "7            0.981149           0.978456           0.974865   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11           0.979354         0.978819        0.000721                1  \n",
       "10           0.978456         0.978639        0.001190                2  \n",
       "8            0.979354         0.978460        0.001502                3  \n",
       "5            0.979354         0.978460        0.001393                4  \n",
       "7            0.979354         0.978281        0.002077                5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fortf-idf\n",
    "rf=RandomForestClassifier()\n",
    "parm={'n_estimators':[10,150,300],\n",
    "      \"max_depth\":[30,60,90,None]}\n",
    "gs=GridSearchCV(rf,parm,cv=5,n_jobs=-1)\n",
    "gs_fit=gs.fit(X_tfidf_feat,data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54.212695</td>\n",
       "      <td>0.917309</td>\n",
       "      <td>0.860433</td>\n",
       "      <td>0.211918</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978998</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29.718315</td>\n",
       "      <td>0.457558</td>\n",
       "      <td>0.615692</td>\n",
       "      <td>0.107907</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.982047</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978819</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49.704287</td>\n",
       "      <td>8.606638</td>\n",
       "      <td>0.668590</td>\n",
       "      <td>0.271470</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978819</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.635619</td>\n",
       "      <td>0.138297</td>\n",
       "      <td>0.494832</td>\n",
       "      <td>0.074756</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.981149</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.978280</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.138273</td>\n",
       "      <td>0.348198</td>\n",
       "      <td>0.495284</td>\n",
       "      <td>0.030901</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.977562</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       54.212695      0.917309         0.860433        0.211918   \n",
       "10      29.718315      0.457558         0.615692        0.107907   \n",
       "11      49.704287      8.606638         0.668590        0.271470   \n",
       "7       28.635619      0.138297         0.494832        0.074756   \n",
       "4       24.138273      0.348198         0.495284        0.030901   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "8               90                300   \n",
       "10            None                150   \n",
       "11            None                300   \n",
       "7               90                150   \n",
       "4               60                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.980269   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.979372   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.979372   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.980269   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}           0.977578   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "8            0.979354           0.978456           0.977558   \n",
       "10           0.982047           0.978456           0.974865   \n",
       "11           0.981149           0.978456           0.975763   \n",
       "7            0.981149           0.977558           0.973070   \n",
       "4            0.979354           0.979354           0.973070   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "8            0.979354         0.978998        0.000920                1  \n",
       "10           0.979354         0.978819        0.002314                2  \n",
       "11           0.979354         0.978819        0.001760                2  \n",
       "7            0.979354         0.978280        0.002864                4  \n",
       "4            0.978456         0.977562        0.002341                5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fortf-idf\n",
    "rf=RandomForestClassifier()\n",
    "parm={'n_estimators':[10,150,300],\n",
    "      \"max_depth\":[30,60,90,None]}\n",
    "gs=GridSearchCV(rf,parm,cv=5,n_jobs=-1)\n",
    "gs_fit=gs.fit(x_count_feat,data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
